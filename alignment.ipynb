{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76c3c878",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-05T17:39:21.235272Z",
          "iopub.status.busy": "2024-08-05T17:39:21.234471Z",
          "iopub.status.idle": "2024-08-05T17:39:35.656027Z",
          "shell.execute_reply": "2024-08-05T17:39:35.655109Z"
        },
        "id": "76c3c878",
        "outputId": "64aa1a81-8934-47f1-f962-518078a51b4b",
        "papermill": {
          "duration": 14.463498,
          "end_time": "2024-08-05T17:39:35.658296",
          "exception": false,
          "start_time": "2024-08-05T17:39:21.194798",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
            "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install trl -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f33100bf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-05T17:39:35.738068Z",
          "iopub.status.busy": "2024-08-05T17:39:35.737396Z",
          "iopub.status.idle": "2024-08-05T17:39:47.981924Z",
          "shell.execute_reply": "2024-08-05T17:39:47.980713Z"
        },
        "papermill": {
          "duration": 12.286088,
          "end_time": "2024-08-05T17:39:47.984460",
          "exception": false,
          "start_time": "2024-08-05T17:39:35.698372",
          "status": "completed"
        },
        "tags": [],
        "id": "f33100bf"
      },
      "outputs": [],
      "source": [
        "!pip install wandb -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1c490cd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-05T17:39:48.063054Z",
          "iopub.status.busy": "2024-08-05T17:39:48.062455Z",
          "iopub.status.idle": "2024-08-05T17:40:00.627777Z",
          "shell.execute_reply": "2024-08-05T17:40:00.626562Z"
        },
        "papermill": {
          "duration": 12.607292,
          "end_time": "2024-08-05T17:40:00.630138",
          "exception": false,
          "start_time": "2024-08-05T17:39:48.022846",
          "status": "completed"
        },
        "tags": [],
        "id": "c1c490cd"
      },
      "outputs": [],
      "source": [
        "!pip install -q pytorch_warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f01d22e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-05T17:40:00.707625Z",
          "iopub.status.busy": "2024-08-05T17:40:00.707012Z",
          "iopub.status.idle": "2024-08-05T17:40:36.629692Z",
          "shell.execute_reply": "2024-08-05T17:40:36.628946Z"
        },
        "id": "5f01d22e",
        "outputId": "2880c006-4e8e-4548-db11-a2fc400d96c8",
        "papermill": {
          "duration": 35.963683,
          "end_time": "2024-08-05T17:40:36.631894",
          "exception": false,
          "start_time": "2024-08-05T17:40:00.668211",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "1ebe10d1484147888dd7c0accfc20faa",
            "c221217041044787b97b1da74b54b4fe",
            "c77b5e559bf34608ad48bcdc8674a15b",
            "61a988edf52a4a1c8d5973dc1d6caf07",
            "5c21463cd61e4c6b8972b6d1ed6b317b",
            "5935984a4d7c488cb7b008a89fff7ca7",
            "1524aa154f734a56a34d5502c587d479"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-08-05 17:40:09.442299: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-05 17:40:09.442413: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-05 17:40:09.563439: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ebe10d1484147888dd7c0accfc20faa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/7.81k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c221217041044787b97b1da74b54b4fe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c77b5e559bf34608ad48bcdc8674a15b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61a988edf52a4a1c8d5973dc1d6caf07",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c21463cd61e4c6b8972b6d1ed6b317b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5935984a4d7c488cb7b008a89fff7ca7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1524aa154f734a56a34d5502c587d479",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "from datasets import Dataset\n",
        "from trl import RewardTrainer, RewardConfig\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, GPT2LMHeadModel\n",
        "import random\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import collections\n",
        "from tqdm import tqdm\n",
        "from copy import deepcopy\n",
        "import pytorch_warmup as warmup\n",
        "\n",
        "data_imdb = load_dataset(\"stanfordnlp/imdb\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "SAVE_REWARD_DIR = \"\"\n",
        "WARP_SAVE_DIR = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4536cf12",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-05T17:40:36.711989Z",
          "iopub.status.busy": "2024-08-05T17:40:36.711359Z",
          "iopub.status.idle": "2024-08-05T17:40:36.720576Z",
          "shell.execute_reply": "2024-08-05T17:40:36.719773Z"
        },
        "id": "4536cf12",
        "papermill": {
          "duration": 0.050725,
          "end_time": "2024-08-05T17:40:36.722556",
          "exception": false,
          "start_time": "2024-08-05T17:40:36.671831",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def build_dataset(tokenizer, input_size, train=True):\n",
        "    if train:\n",
        "        data_generator = zip(data_imdb['train'][len(data_imdb['train']) // 2:]['text'],\n",
        "                             data_imdb['train'][:len(data_imdb['train']) // 2]['text'])\n",
        "    else:\n",
        "        data_generator = zip(data_imdb['test'][-100:]['text'],\n",
        "                             data_imdb['test'][:100]['text'])\n",
        "    def gen():\n",
        "        for x in data_generator:\n",
        "            yield {\"chosen\": x[0], \"rejected\": x[1]}\n",
        "    pairs = Dataset.from_generator(gen)\n",
        "\n",
        "    def tokenize(sample):\n",
        "        dict_chosen = tokenizer(sample[\"chosen\"])\n",
        "        sample[\"input_ids_chosen\"] = dict_chosen[\"input_ids\"][: input_size]\n",
        "        sample[\"attention_mask_chosen\"] = dict_chosen[\"attention_mask\"][: input_size]\n",
        "\n",
        "        dict_rejected = tokenizer(sample[\"rejected\"])\n",
        "        sample[\"input_ids_rejected\"] = dict_rejected[\"input_ids\"][: input_size]\n",
        "        sample[\"attention_mask_rejected\"] = dict_rejected[\"attention_mask\"][: input_size]\n",
        "        return sample\n",
        "    ds = pairs.map(tokenize)\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "453a9799",
      "metadata": {
        "id": "453a9799",
        "papermill": {
          "duration": 0.038527,
          "end_time": "2024-08-05T17:40:36.799787",
          "exception": false,
          "start_time": "2024-08-05T17:40:36.761260",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Training reward model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acb22d23",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-05T17:40:36.878385Z",
          "iopub.status.busy": "2024-08-05T17:40:36.878090Z",
          "iopub.status.idle": "2024-08-05T17:40:36.882003Z",
          "shell.execute_reply": "2024-08-05T17:40:36.881147Z"
        },
        "id": "acb22d23",
        "papermill": {
          "duration": 0.045669,
          "end_time": "2024-08-05T17:40:36.883907",
          "exception": false,
          "start_time": "2024-08-05T17:40:36.838238",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "base_model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-cased\")\n",
        "base_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")\n",
        "reward_config = RewardConfig(output_dir=\"model\", num_train_epochs=5, learning_rate=1e-5)\n",
        "\n",
        "base_tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "base_model.resize_token_embeddings(len(base_tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9025d3df",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-05T17:40:36.962601Z",
          "iopub.status.busy": "2024-08-05T17:40:36.962297Z",
          "iopub.status.idle": "2024-08-05T17:40:36.966224Z",
          "shell.execute_reply": "2024-08-05T17:40:36.965242Z"
        },
        "papermill": {
          "duration": 0.045593,
          "end_time": "2024-08-05T17:40:36.968193",
          "exception": false,
          "start_time": "2024-08-05T17:40:36.922600",
          "status": "completed"
        },
        "tags": [],
        "id": "9025d3df"
      },
      "outputs": [],
      "source": [
        "input_size = 7\n",
        "ds = build_dataset(base_tokenizer, input_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba870122",
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-08-05T17:40:37.047654Z",
          "iopub.status.busy": "2024-08-05T17:40:37.046943Z",
          "iopub.status.idle": "2024-08-05T17:40:37.050947Z",
          "shell.execute_reply": "2024-08-05T17:40:37.050057Z"
        },
        "id": "ba870122",
        "jupyter": {
          "outputs_hidden": true
        },
        "papermill": {
          "duration": 0.045816,
          "end_time": "2024-08-05T17:40:37.052814",
          "exception": false,
          "start_time": "2024-08-05T17:40:37.006998",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "trainer = RewardTrainer(model=base_model,\n",
        "                        tokenizer=base_tokenizer,\n",
        "                        train_dataset=ds,\n",
        "                        args=reward_config)\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71f5c1a2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-05T17:40:37.175716Z",
          "iopub.status.busy": "2024-08-05T17:40:37.174929Z",
          "iopub.status.idle": "2024-08-05T17:40:37.179267Z",
          "shell.execute_reply": "2024-08-05T17:40:37.178355Z"
        },
        "id": "71f5c1a2",
        "papermill": {
          "duration": 0.089548,
          "end_time": "2024-08-05T17:40:37.181204",
          "exception": false,
          "start_time": "2024-08-05T17:40:37.091656",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"SAVE_REWARD_DIR\")\n",
        "!zip -r SAVE_REWARD_DIR.zip SAVE_REWARD_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f620a5df",
      "metadata": {
        "id": "f620a5df",
        "papermill": {
          "duration": 0.04026,
          "end_time": "2024-08-05T17:40:37.260733",
          "exception": false,
          "start_time": "2024-08-05T17:40:37.220473",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Training WARP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdeaa072",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-05T17:40:37.446067Z",
          "iopub.status.busy": "2024-08-05T17:40:37.445429Z",
          "iopub.status.idle": "2024-08-05T17:41:06.999473Z",
          "shell.execute_reply": "2024-08-05T17:41:06.998650Z"
        },
        "id": "cdeaa072",
        "papermill": {
          "duration": 29.599599,
          "end_time": "2024-08-05T17:41:07.001868",
          "exception": false,
          "start_time": "2024-08-05T17:40:37.402269",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "c30c16e7538b4e4abbbec77f3a8374ba",
            "37d7abdb9ce84de0b05f969f374acc82",
            "216850ec43eb4859a6f97c9fc63c9d9a",
            "70fbe87c0bb74e56982bd63cc51faa33",
            "7fcb9b7b1868437b82baa1c5e69df6b3",
            "3453a65c74f646989fec3bce8f17b8c4"
          ]
        },
        "outputId": "17b2a57f-9b7f-4330-a1cd-a2093fc5a4a9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c30c16e7538b4e4abbbec77f3a8374ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/577 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37d7abdb9ce84de0b05f969f374acc82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "216850ec43eb4859a6f97c9fc63c9d9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/17.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70fbe87c0bb74e56982bd63cc51faa33",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7fcb9b7b1868437b82baa1c5e69df6b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3453a65c74f646989fec3bce8f17b8c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "reward_model = AutoModelForSequenceClassification.from_pretrained(SAVE_REWARD_DIR, local_files_only=True).to(device)\n",
        "sft_model = GPT2LMHeadModel.from_pretrained(\"lvwerra/gpt2-imdb\").to(device)\n",
        "sft_tokenizer = AutoTokenizer.from_pretrained(\"lvwerra/gpt2-imdb\", padding_side=\"left\")\n",
        "anchor_model = GPT2LMHeadModel.from_pretrained(\"lvwerra/gpt2-imdb\").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b661787",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-05T17:41:07.083882Z",
          "iopub.status.busy": "2024-08-05T17:41:07.083519Z",
          "iopub.status.idle": "2024-08-05T17:41:07.122300Z",
          "shell.execute_reply": "2024-08-05T17:41:07.121393Z"
        },
        "id": "8b661787",
        "papermill": {
          "duration": 0.08194,
          "end_time": "2024-08-05T17:41:07.124448",
          "exception": false,
          "start_time": "2024-08-05T17:41:07.042508",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "sft_tokenizer.pad_token_id = sft_tokenizer.eos_token_id\n",
        "sft_model.resize_token_embeddings(len(sft_tokenizer))\n",
        "sft_model.config.pad_token_id = sft_tokenizer.pad_token_id\n",
        "\n",
        "reward_model.resize_token_embeddings(len(sft_tokenizer))\n",
        "reward_model.config.pad_token_id = sft_tokenizer.pad_token_id\n",
        "\n",
        "anchor_model.resize_token_embeddings(len(sft_tokenizer))\n",
        "anchor_model.config.pad_token_id = sft_tokenizer.pad_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddffe008",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-05T17:41:07.206602Z",
          "iopub.status.busy": "2024-08-05T17:41:07.206295Z",
          "iopub.status.idle": "2024-08-05T17:41:09.723979Z",
          "shell.execute_reply": "2024-08-05T17:41:09.723035Z"
        },
        "papermill": {
          "duration": 2.561079,
          "end_time": "2024-08-05T17:41:09.726033",
          "exception": false,
          "start_time": "2024-08-05T17:41:07.164954",
          "status": "completed"
        },
        "tags": [],
        "id": "ddffe008",
        "outputId": "d106b21f-d0bb-45f0-bfb0-42446f74cd06"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13b6e7a2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-05T17:41:09.809400Z",
          "iopub.status.busy": "2024-08-05T17:41:09.809078Z",
          "iopub.status.idle": "2024-08-05T17:41:09.814945Z",
          "shell.execute_reply": "2024-08-05T17:41:09.814084Z"
        },
        "id": "13b6e7a2",
        "papermill": {
          "duration": 0.049654,
          "end_time": "2024-08-05T17:41:09.816886",
          "exception": false,
          "start_time": "2024-08-05T17:41:09.767232",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def collator(data):\n",
        "    batches = []\n",
        "    for i in range(0, len(data), batch_size):\n",
        "        cur_data = data[i:min(len(data), i + batch_size)]\n",
        "        batch = {}\n",
        "        batch['input_ids'] = torch.tensor(cur_data['input_ids_chosen'] + cur_data['input_ids_rejected'])\n",
        "        batch['attention_mask'] = torch.tensor(cur_data['attention_mask_chosen'] + cur_data['attention_mask_rejected'])\n",
        "        batches.append(batch)\n",
        "    return batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c20107a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-05T17:41:09.900073Z",
          "iopub.status.busy": "2024-08-05T17:41:09.899762Z",
          "iopub.status.idle": "2024-08-05T17:41:37.883836Z",
          "shell.execute_reply": "2024-08-05T17:41:37.882842Z"
        },
        "id": "2c20107a",
        "papermill": {
          "duration": 28.028218,
          "end_time": "2024-08-05T17:41:37.885909",
          "exception": false,
          "start_time": "2024-08-05T17:41:09.857691",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "f1135da56dd6472dba47d15ff3545205",
            "0c27510e90ca4124b2d7bd462a04e16b"
          ]
        },
        "outputId": "bcb06e1a-c4c5-4a4a-887d-763fa2a9386a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1135da56dd6472dba47d15ff3545205",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c27510e90ca4124b2d7bd462a04e16b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/12500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([64, 7])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_size = 7\n",
        "ds = build_dataset(sft_tokenizer, input_size)\n",
        "\n",
        "batch_size = 32\n",
        "ds_batched = collator(ds)\n",
        "ds_batched[0]['input_ids'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c3d29fb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-05T17:41:38.059141Z",
          "iopub.status.busy": "2024-08-05T17:41:38.058850Z",
          "iopub.status.idle": "2024-08-05T17:41:38.064155Z",
          "shell.execute_reply": "2024-08-05T17:41:38.063285Z"
        },
        "id": "9c3d29fb",
        "papermill": {
          "duration": 0.04886,
          "end_time": "2024-08-05T17:41:38.066087",
          "exception": false,
          "start_time": "2024-08-05T17:41:38.017227",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def adjusted_kl_loss(y_ema, y_m):\n",
        "    log_ym = torch.log(y_m)\n",
        "    log_yma = torch.log(y_ema)\n",
        "\n",
        "    kl_loss = F.kl_div(log_ym, log_yma, log_target=True, reduction=\"batchmean\")\n",
        "    reward = reward_model(y_m.argmax(axis=2)).logits.mean() - beta * kl_loss\n",
        "    return -reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "993deec9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-05T17:41:38.148840Z",
          "iopub.status.busy": "2024-08-05T17:41:38.148520Z",
          "iopub.status.idle": "2024-08-05T17:41:38.153157Z",
          "shell.execute_reply": "2024-08-05T17:41:38.152374Z"
        },
        "id": "993deec9",
        "papermill": {
          "duration": 0.048226,
          "end_time": "2024-08-05T17:41:38.154962",
          "exception": false,
          "start_time": "2024-08-05T17:41:38.106736",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def update_theta_ema(theta_ema, theta_m):\n",
        "    theta_ema_new = {}\n",
        "    for key in theta_ema.keys():\n",
        "        theta_ema_new[key] = (1 - mu) * theta_ema[key] + mu * theta_m[key]\n",
        "    return theta_ema_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed725608",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-05T17:41:38.237955Z",
          "iopub.status.busy": "2024-08-05T17:41:38.237670Z",
          "iopub.status.idle": "2024-08-05T17:41:38.248800Z",
          "shell.execute_reply": "2024-08-05T17:41:38.247976Z"
        },
        "id": "ed725608",
        "papermill": {
          "duration": 0.054885,
          "end_time": "2024-08-05T17:41:38.250604",
          "exception": false,
          "start_time": "2024-08-05T17:41:38.195719",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def inner_cycle(theta_init, run_name):\n",
        "    '''\n",
        "    training cycle from the paper\n",
        "    '''\n",
        "    run = wandb.init(project=\"second_try\", name=run_name, reinit=True)\n",
        "    cfg = wandb.config\n",
        "    cfg.update({\"T\" : T, \"batch_size\": batch_size, \"lr\" : 1e-6,\n",
        "                \"M\": M, \"I\": I, \"beta\": beta, \"mu\": mu, \"eta\": eta, \"warmup\": 10})\n",
        "    anchor_model.load_state_dict(theta_init)\n",
        "    sft_model.load_state_dict(theta_init)\n",
        "    theta_m, theta_ema = sft_model.state_dict(), anchor_model.state_dict()\n",
        "\n",
        "    optimizer = torch.optim.Adam(sft_model.parameters(), lr=1e-6)\n",
        "    mean_kl_loss = 0\n",
        "    for t in tqdm(range(T), desc=\"Training: \"):\n",
        "        for i, batch in enumerate(ds_batched):\n",
        "            optimizer.zero_grad()\n",
        "            input_ids, attention_mask = batch['input_ids'].to(device), batch['attention_mask'].to(device)\n",
        "            logits_m = sft_model(input_ids=input_ids,\n",
        "                                 attention_mask=attention_mask).logits[:, :, input_size-1:-1]\n",
        "            logits_ema = anchor_model(input_ids=input_ids,\n",
        "                                    attention_mask=attention_mask).logits[:, :, input_size-1:-1]\n",
        "\n",
        "            ema_dist = torch.clamp(F.softmax(logits_ema, dim=2), min=1e-9, max=1.)\n",
        "            m_dist = torch.clamp(F.softmax(logits_m, dim=2), min=1e-9, max=1.)\n",
        "            kl_loss = adjusted_kl_loss(ema_dist, m_dist)\n",
        "            mean_kl_loss += kl_loss.item()\n",
        "\n",
        "            kl_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            theta_ema = update_theta_ema(theta_m, theta_ema)\n",
        "        wandb.log({\"reward\" : abs(mean_kl_loss) / len(ds_batched)})\n",
        "    run.finish()\n",
        "    return theta_m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7735cfd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-05T17:41:38.333662Z",
          "iopub.status.busy": "2024-08-05T17:41:38.333357Z",
          "iopub.status.idle": "2024-08-05T17:41:38.354917Z",
          "shell.execute_reply": "2024-08-05T17:41:38.354056Z"
        },
        "id": "b7735cfd",
        "papermill": {
          "duration": 0.06569,
          "end_time": "2024-08-05T17:41:38.356894",
          "exception": false,
          "start_time": "2024-08-05T17:41:38.291204",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "theta_init = deepcopy(sft_model.state_dict())\n",
        "I = 2\n",
        "M = 2\n",
        "T = 10\n",
        "beta = 0.1\n",
        "mu = 0.01\n",
        "eta = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca0c57a3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-05T17:41:38.440679Z",
          "iopub.status.busy": "2024-08-05T17:41:38.440143Z",
          "iopub.status.idle": "2024-08-05T17:41:38.445035Z",
          "shell.execute_reply": "2024-08-05T17:41:38.444175Z"
        },
        "id": "ca0c57a3",
        "papermill": {
          "duration": 0.048534,
          "end_time": "2024-08-05T17:41:38.446996",
          "exception": false,
          "start_time": "2024-08-05T17:41:38.398462",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def get_task_vector(pretrained_state_dict, finetuned_state_dict):\n",
        "    with torch.no_grad():\n",
        "        vector = {}\n",
        "        for key in pretrained_state_dict.keys():\n",
        "            vector[key] = finetuned_state_dict[key] - pretrained_state_dict[key]\n",
        "    return vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47bdd6d2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-05T17:41:38.530922Z",
          "iopub.status.busy": "2024-08-05T17:41:38.530662Z",
          "iopub.status.idle": "2024-08-05T17:41:38.539185Z",
          "shell.execute_reply": "2024-08-05T17:41:38.538117Z"
        },
        "id": "47bdd6d2",
        "papermill": {
          "duration": 0.052773,
          "end_time": "2024-08-05T17:41:38.541275",
          "exception": false,
          "start_time": "2024-08-05T17:41:38.488502",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def slerp(theta_init, theta_1, theta_2, lambda_):\n",
        "    def find_angle(v1, v2):\n",
        "        dot_product = (torch.flatten(v1) * torch.flatten(v2)).sum()\n",
        "        cos_angle = torch.clamp((dot_product / (torch.linalg.vector_norm(v1) * torch.linalg.vector_norm(v2))), min=-1., max=1.).item()\n",
        "        return np.arccos(cos_angle), np.arccos(cos_angle) * 180 / torch.pi\n",
        "\n",
        "    delta_1 = get_task_vector(theta_init, theta_1)\n",
        "    delta_2 = get_task_vector(theta_init, theta_2)\n",
        "\n",
        "    theta_fin = {}\n",
        "    for key in delta_1.keys():\n",
        "        omega_radian, omega_degrees = find_angle(delta_1[key], delta_2[key])\n",
        "        if abs(np.sin(omega_radian)) > 1e-7:\n",
        "            theta_fin[key] = theta_init[key] \\\n",
        "            + np.sin((1 - lambda_) * omega_degrees) / np.sin(omega_radian) * delta_1[key] \\\n",
        "            + np.sin(lambda_ * omega_degrees) / np.sin(omega_radian) * delta_2[key]\n",
        "        else:\n",
        "            theta_fin[key] = theta_init[key]\n",
        "    return theta_fin\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad2ea479",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-05T17:41:38.624311Z",
          "iopub.status.busy": "2024-08-05T17:41:38.623820Z",
          "iopub.status.idle": "2024-08-05T17:41:38.630212Z",
          "shell.execute_reply": "2024-08-05T17:41:38.629396Z"
        },
        "id": "ad2ea479",
        "papermill": {
          "duration": 0.049687,
          "end_time": "2024-08-05T17:41:38.631949",
          "exception": false,
          "start_time": "2024-08-05T17:41:38.582262",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def warp(theta_init):\n",
        "    def update_theta_init(theta_init, theta_slerp, eta):\n",
        "        for key in theta_init.keys():\n",
        "            theta_init[key] = (1 - eta) * theta_init[key] + eta * theta_slerp[key]\n",
        "        return theta_init\n",
        "\n",
        "    for i in range(I):\n",
        "        theta_1 = inner_cycle(theta_init, \"first_run\")\n",
        "        torch.save(theta_1, f\"theta1_{i}.pth\")\n",
        "\n",
        "        theta_2 = inner_cycle(theta_init, \"second_run\")\n",
        "        torch.save(theta_2, f\"theta2_{i}.pth\")\n",
        "\n",
        "        theta_slerp = slerp(theta_init, theta_1, theta_2, 0.5)\n",
        "        theta_init = update_theta_init(theta_init, theta_slerp, eta)\n",
        "    return theta_init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f59e905",
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-08-05T17:41:38.714878Z",
          "iopub.status.busy": "2024-08-05T17:41:38.714583Z",
          "iopub.status.idle": "2024-08-05T18:36:30.992358Z",
          "shell.execute_reply": "2024-08-05T18:36:30.991329Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "papermill": {
          "duration": 3292.321953,
          "end_time": "2024-08-05T18:36:30.994904",
          "exception": false,
          "start_time": "2024-08-05T17:41:38.672951",
          "status": "completed"
        },
        "tags": [],
        "id": "8f59e905",
        "outputId": "76593746-3913-4281-d864-a14de05ead0b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mntyazh\u001b[0m (\u001b[33mntyazh-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.5 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20240805_174138-g2a16csy\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfirst_run\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ntyazh-team/second_try\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ntyazh-team/second_try/runs/g2a16csy\u001b[0m\n",
            "Training: 100%|██████████| 10/10 [13:20<00:00, 80.04s/it]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: reward ▁▂▃▃▄▅▆▆▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: reward 0.43794\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mfirst_run\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ntyazh-team/second_try/runs/g2a16csy\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ntyazh-team/second_try\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240805_174138-g2a16csy/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.5 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20240805_175523-reymjet0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msecond_run\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ntyazh-team/second_try\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ntyazh-team/second_try/runs/reymjet0\u001b[0m\n",
            "Training: 100%|██████████| 10/10 [13:20<00:00, 80.01s/it]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: reward ▁▂▃▃▄▅▆▆▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: reward 0.43794\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msecond_run\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ntyazh-team/second_try/runs/reymjet0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ntyazh-team/second_try\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240805_175523-reymjet0/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.5 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20240805_180906-gvywmde1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfirst_run\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ntyazh-team/second_try\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ntyazh-team/second_try/runs/gvywmde1\u001b[0m\n",
            "Training: 100%|██████████| 10/10 [13:19<00:00, 80.00s/it]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: reward ▁▂▃▃▄▅▆▆▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: reward 0.43809\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mfirst_run\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ntyazh-team/second_try/runs/gvywmde1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ntyazh-team/second_try\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240805_180906-gvywmde1/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.5 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20240805_182248-s1gaf7d0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msecond_run\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ntyazh-team/second_try\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ntyazh-team/second_try/runs/s1gaf7d0\u001b[0m\n",
            "Training: 100%|██████████| 10/10 [13:19<00:00, 80.00s/it]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: reward ▁▂▃▃▄▅▆▆▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: reward 0.43809\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msecond_run\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ntyazh-team/second_try/runs/s1gaf7d0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ntyazh-team/second_try\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240805_182248-s1gaf7d0/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n"
          ]
        }
      ],
      "source": [
        "theta_fin = warp(theta_init)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f398b51",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-05T18:36:31.096992Z",
          "iopub.status.busy": "2024-08-05T18:36:31.096676Z",
          "iopub.status.idle": "2024-08-05T18:36:32.120275Z",
          "shell.execute_reply": "2024-08-05T18:36:32.119448Z"
        },
        "papermill": {
          "duration": 1.076692,
          "end_time": "2024-08-05T18:36:32.122487",
          "exception": false,
          "start_time": "2024-08-05T18:36:31.045795",
          "status": "completed"
        },
        "tags": [],
        "id": "5f398b51"
      },
      "outputs": [],
      "source": [
        "torch.save(theta_fin, f\"{WARP_SAVE_DIR}.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c486543",
      "metadata": {
        "papermill": {
          "duration": 0.049638,
          "end_time": "2024-08-05T18:36:32.223199",
          "exception": false,
          "start_time": "2024-08-05T18:36:32.173561",
          "status": "completed"
        },
        "tags": [],
        "id": "6c486543"
      },
      "source": [
        "# SFT-model VS trained WARP-model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e891576a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-05T18:36:32.324082Z",
          "iopub.status.busy": "2024-08-05T18:36:32.323772Z",
          "iopub.status.idle": "2024-08-05T18:36:34.706136Z",
          "shell.execute_reply": "2024-08-05T18:36:34.705334Z"
        },
        "papermill": {
          "duration": 2.435937,
          "end_time": "2024-08-05T18:36:34.708597",
          "exception": false,
          "start_time": "2024-08-05T18:36:32.272660",
          "status": "completed"
        },
        "tags": [],
        "id": "e891576a"
      },
      "outputs": [],
      "source": [
        "sft_model = GPT2LMHeadModel.from_pretrained(\"lvwerra/gpt2-imdb\").to(device)\n",
        "sft_tokenizer = AutoTokenizer.from_pretrained(\"lvwerra/gpt2-imdb\", padding_side=\"left\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a03ea54",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-05T18:36:34.810083Z",
          "iopub.status.busy": "2024-08-05T18:36:34.809792Z",
          "iopub.status.idle": "2024-08-05T18:36:34.823126Z",
          "shell.execute_reply": "2024-08-05T18:36:34.822449Z"
        },
        "papermill": {
          "duration": 0.065754,
          "end_time": "2024-08-05T18:36:34.824909",
          "exception": false,
          "start_time": "2024-08-05T18:36:34.759155",
          "status": "completed"
        },
        "tags": [],
        "id": "3a03ea54"
      },
      "outputs": [],
      "source": [
        "sft_tokenizer.pad_token_id = sft_tokenizer.eos_token_id\n",
        "sft_model.resize_token_embeddings(len(sft_tokenizer))\n",
        "sft_model.config.pad_token_id = sft_tokenizer.pad_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0afc534",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-05T18:36:34.925358Z",
          "iopub.status.busy": "2024-08-05T18:36:34.925090Z",
          "iopub.status.idle": "2024-08-05T18:36:37.197699Z",
          "shell.execute_reply": "2024-08-05T18:36:37.196888Z"
        },
        "papermill": {
          "duration": 2.32544,
          "end_time": "2024-08-05T18:36:37.199949",
          "exception": false,
          "start_time": "2024-08-05T18:36:34.874509",
          "status": "completed"
        },
        "tags": [],
        "id": "b0afc534"
      },
      "outputs": [],
      "source": [
        "warp_model = GPT2LMHeadModel.from_pretrained(\"lvwerra/gpt2-imdb\").to(device)\n",
        "warp_model.load_state_dict(torch.load(WARP_SAVE_DIR))\n",
        "warp_model.resize_token_embeddings(len(sft_tokenizer))\n",
        "warp_model.config.pad_token_id = sft_tokenizer.pad_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56ea391d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-05T18:36:37.306535Z",
          "iopub.status.busy": "2024-08-05T18:36:37.306234Z",
          "iopub.status.idle": "2024-08-05T18:36:37.652845Z",
          "shell.execute_reply": "2024-08-05T18:36:37.651958Z"
        },
        "papermill": {
          "duration": 0.399538,
          "end_time": "2024-08-05T18:36:37.654724",
          "exception": false,
          "start_time": "2024-08-05T18:36:37.255186",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "8196b4862dab483aaf7ad95d5f1310a0",
            "1d0b4bd1b41c49469b8bb68ca4f28e4f"
          ]
        },
        "id": "56ea391d",
        "outputId": "d0aaddb5-11fa-426c-b609-2fed4182acb1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8196b4862dab483aaf7ad95d5f1310a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d0b4bd1b41c49469b8bb68ca4f28e4f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([64, 7])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_size = 7\n",
        "ds = build_dataset(sft_tokenizer, input_size, train=False)\n",
        "\n",
        "batch_size = 32\n",
        "ds_batched = collator(ds)\n",
        "ds_batched[0]['input_ids'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85294ad6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-05T18:36:37.757046Z",
          "iopub.status.busy": "2024-08-05T18:36:37.756739Z",
          "iopub.status.idle": "2024-08-05T18:36:38.002061Z",
          "shell.execute_reply": "2024-08-05T18:36:38.000995Z"
        },
        "papermill": {
          "duration": 0.298349,
          "end_time": "2024-08-05T18:36:38.003931",
          "exception": false,
          "start_time": "2024-08-05T18:36:37.705582",
          "status": "completed"
        },
        "tags": [],
        "id": "85294ad6",
        "outputId": "32eab6e4-6236-4e08-8f72-621028115272"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean SFT reward: 0.0438411\n",
            "Mean WARP reward: 0.0438410\n",
            "\n",
            "Mean KL(sft||warp): 0.02546\n",
            "Mean KL(warp||sft): 0.02410 \n"
          ]
        }
      ],
      "source": [
        "mean_kl_sft = 0\n",
        "mean_kl_warp = 0\n",
        "mean_reward_sft, mean_reward_warp = 0, 0\n",
        "with torch.no_grad():\n",
        "    for i, batch in enumerate(ds_batched):\n",
        "        input_ids, attention_mask = batch['input_ids'].to(device), batch['attention_mask'].to(device)\n",
        "        logits_sft = sft_model(input_ids=input_ids,\n",
        "                                             attention_mask=attention_mask).logits[:, :, input_size-1:-1]\n",
        "        logits_warp = warp_model(input_ids=input_ids,\n",
        "                                 attention_mask=attention_mask).logits[:, :, input_size-1:-1]\n",
        "\n",
        "\n",
        "        sft_dist = torch.clamp(F.softmax(logits_sft, dim=2), min=1e-9, max=1.)\n",
        "        warp_dist = torch.clamp(F.softmax(logits_warp, dim=2), min=1e-9, max=1.)\n",
        "        log_sft_dist = torch.log(sft_dist)\n",
        "        log_warp_dist = torch.log(warp_dist)\n",
        "\n",
        "        kl_loss_sft = F.kl_div(log_sft_dist, log_warp_dist, log_target=True, reduction=\"batchmean\")\n",
        "        kl_loss_warp = F.kl_div(log_warp_dist, log_sft_dist, log_target=True, reduction=\"batchmean\")\n",
        "        reward_sft = reward_model(sft_dist.argmax(axis=2)).logits.mean()\n",
        "        reward_warp = reward_model(warp_dist.argmax(axis=2)).logits.mean()\n",
        "\n",
        "        mean_kl_sft += kl_loss_sft\n",
        "        mean_kl_warp += kl_loss_warp\n",
        "        mean_reward_sft += reward_sft\n",
        "        mean_reward_warp += reward_warp\n",
        "\n",
        "print(f\"Mean SFT reward: {mean_reward_sft / len(ds_batched):.7f}\\nMean WARP reward: {mean_reward_warp / len(ds_batched):.7f}\\n\")\n",
        "print(f\"Mean KL(sft||warp): {mean_kl_sft / len(ds_batched):.5f}\\nMean KL(warp||sft): {mean_kl_warp / len(ds_batched):.5f} \")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "isSourceIdPinned": true,
          "modelId": 99849,
          "modelInstanceId": 75128,
          "sourceId": 89561,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 30747,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 3442.4283,
      "end_time": "2024-08-05T18:36:40.784794",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-08-05T17:39:18.356494",
      "version": "2.5.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}